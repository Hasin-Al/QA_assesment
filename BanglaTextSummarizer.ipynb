{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulub440Etpc7",
        "outputId": "e6576467-eb5e-42b5-b0f8-c6cda29ebfa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounting drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bum27Glwt6ny",
        "outputId": "bc9faba1-89b8-4a6f-fe4b-99bb038d4202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bnlp_toolkit\n",
            "  Downloading bnlp_toolkit-4.0.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.2.0)\n",
            "Collecting gensim==4.3.2 (from bnlp_toolkit)\n",
            "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.26.4)\n",
            "Collecting scipy==1.10.1 (from bnlp_toolkit)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn-crfsuite==0.3.6 (from bnlp_toolkit)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting tqdm==4.66.3 (from bnlp_toolkit)\n",
            "  Downloading tqdm-4.66.3-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.2.0 (from bnlp_toolkit)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting emoji==1.7.0 (from bnlp_toolkit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (2.32.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.2.0->bnlp_toolkit) (0.2.13)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.3.2->bnlp_toolkit) (7.0.5)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite==0.3.6->bnlp_toolkit)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bnlp_toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6->bnlp_toolkit) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2024.8.30)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim==4.3.2->bnlp_toolkit) (1.16.0)\n",
            "Downloading bnlp_toolkit-4.0.3-py3-none-any.whl (22 kB)\n",
            "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Downloading tqdm-4.66.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=bdc056af5c4154e650935f2e011e6c88aeb8c8afb64eb9e719e9cfa74fadf2aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, tqdm, scipy, python-crfsuite, ftfy, sklearn-crfsuite, gensim, bnlp_toolkit\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.6\n",
            "    Uninstalling tqdm-4.66.6:\n",
            "      Successfully uninstalled tqdm-4.66.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "Successfully installed bnlp_toolkit-4.0.3 emoji-1.7.0 ftfy-6.2.0 gensim-4.3.2 python-crfsuite-0.9.11 scipy-1.10.1 sklearn-crfsuite-0.3.6 tqdm-4.66.3\n"
          ]
        }
      ],
      "source": [
        "#installing bnlp_toolkit\n",
        "!pip install bnlp_toolkit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY8eicz2t6qi",
        "outputId": "b60e8961-7aad-4c8e-a491-9ff9a2e4272d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "punkt not found. downloading...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#imporing libraris\n",
        "#importing all necessari libraries . For tokenization we will use bnlp tokenizer and create our own embedder\n",
        "from bnlp import NLTKTokenizer\n",
        "import string\n",
        "from bnlp import CleanText\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47MR_0hCt6tC"
      },
      "outputs": [],
      "source": [
        "#reading dataset from drive\n",
        "data = pd.read_csv('/content/drive/MyDrive/bangladeshnewsData.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzzPpDDvt6vb"
      },
      "outputs": [],
      "source": [
        "#defined function\n",
        "#Here we define some functions for our later use\n",
        "\n",
        "tokenizer = NLTKTokenizer()\n",
        "clean_text = CleanText(\n",
        "   fix_unicode=True,\n",
        "   unicode_norm=True,\n",
        "   unicode_norm_form=\"NFKC\",\n",
        "   remove_url=False,\n",
        "   remove_email=True,\n",
        "   remove_emoji=True,\n",
        "   remove_number=True,\n",
        "   remove_digits=True,\n",
        "   remove_punct=True,\n",
        "   replace_with_url=\"<URL>\",\n",
        "   replace_with_email=\"<EMAIL>\",\n",
        "   replace_with_number=\"<NUMBER>\",\n",
        "   replace_with_digit=\"<DIGIT>\",\n",
        "   replace_with_punct = \"\"\n",
        ")\n",
        "\n",
        "def remove_hyphens(text):\n",
        "    # Remove hyphens from the text\n",
        "    cleaned_text = text.replace('\\u002D', '')\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_unwanted_char(text):\n",
        "  cleaned_text = text.replace('—','')\n",
        "  cleaned_text = cleaned_text.replace('<','')\n",
        "  cleaned_text = cleaned_text.replace('>','')\n",
        "  cleaned_text = cleaned_text.replace('/','')\n",
        "  cleaned_text = cleaned_text.replace('...','')\n",
        "\n",
        "  return cleaned_text\n",
        "\n",
        "# Chunk text function remains the same\n",
        "def chunk_text(text, chunk_size=100):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "def remove_parentheses_and_text(lines):\n",
        "    cleaned_lines = [re.sub(r'\\([^)]*\\)', '', line) for line in lines]\n",
        "    return cleaned_lines\n",
        "\n",
        "def is_bangla(text):\n",
        "    bangla_pattern = re.compile(r'^[\\u0980-\\u09FF\\s]+$')\n",
        "    return bool(bangla_pattern.match(text))\n",
        "\n",
        "def preprocess(text):\n",
        "  text = clean_text(text)\n",
        "  text = remove_hyphens(text)\n",
        "  text = remove_unwanted_char(text)\n",
        "  text = remove_parentheses_and_text(text)\n",
        "  #text = is_bangla(text)\n",
        "\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6szv0i2zuPfx"
      },
      "outputs": [],
      "source": [
        "#As our target is to use sentence embedder\n",
        "#This functions will separate bangla complete sentences based line ending punctuations\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    sentence_endings = ['।', '?', '!']\n",
        "    sentences = []\n",
        "    for punctuation in sentence_endings:\n",
        "        sentences.extend([s.strip() for s in text.split(punctuation) if s.strip()])\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def new_split_sentences(text):\n",
        "\n",
        "    sentences = re.split(r'[।?!]', text)\n",
        "\n",
        "    return [s.strip() for s in sentences if s.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMoZfDGKuTFp"
      },
      "outputs": [],
      "source": [
        "#separate complete sentences and add into a list\n",
        "text_list = data['Description'].apply(new_split_sentences).to_list()\n",
        "summary_list = data['Summary'].apply(new_split_sentences).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeDcNlK9uV6h"
      },
      "outputs": [],
      "source": [
        "#processing texts\n",
        "# separate function to process text and summary\n",
        "def text_preprocess(text_data):\n",
        "    processed_text = []\n",
        "\n",
        "\n",
        "    for document in text_data:\n",
        "        processed_document = []\n",
        "        for sentence in document:\n",
        "\n",
        "            temp = clean_text(sentence)\n",
        "            temp = remove_hyphens(temp)\n",
        "            temp = remove_unwanted_char(temp)\n",
        "            processed_document.append(temp)\n",
        "\n",
        "        t\n",
        "        processed_text.append(processed_document)\n",
        "\n",
        "    # Replace '/n' with space (if needed)\n",
        "    #processed_text = [[[t.replace('/n', \" \")] for t in document] for document in processed_text]\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "def summary_preprocess(text_data):\n",
        "    processed_text = []\n",
        "    for document in text_data:\n",
        "        processed_document = []\n",
        "        for sentence in document:\n",
        "\n",
        "            temp = clean_text(sentence)\n",
        "            temp = remove_hyphens(temp)\n",
        "            temp = remove_unwanted_char(temp)\n",
        "            processed_document.append(temp)\n",
        "\n",
        "        processed_text.append(processed_document)\n",
        "        #print(processed_text)\n",
        "        #break\n",
        "\n",
        "    # Replace '/n' with space (if needed)\n",
        "    #processed_text = [[[t.replace('/n', \" \")] for t in document] for document in processed_text]\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iscbt3wuZ8g"
      },
      "outputs": [],
      "source": [
        "#preprocess text and summary\n",
        "text_data = text_preprocess(text_list)\n",
        "summary_data = summary_preprocess(summary_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "60EMoYnuOIae"
      },
      "outputs": [],
      "source": [
        "# Function to remove non-Bengali words\n",
        "def remove_non_bengali_words(text_list):\n",
        "    bengali_pattern = r'[^\\u0980-\\u09FF\\s]'\n",
        "    cleaned_text = [\n",
        "        [\n",
        "            re.sub(bengali_pattern, '', sentence).strip()\n",
        "            for sentence in sublist\n",
        "        ]\n",
        "        for sublist in text_list\n",
        "    ]\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "wBmnS9mDb7EV"
      },
      "outputs": [],
      "source": [
        "# remove non bengali words from text and summary\n",
        "text_data = remove_non_bengali_words(text_data)\n",
        "summary_data = remove_non_bengali_words(summary_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "c499u5-8OSDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e8af98-8dd9-440f-d3a6-dde5761766e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['গাজীপুরে ছেলে হত্যার বিচার চাইতে গিয়ে প্রতিপক্ষের মারধরে পোশাকশ্রমিক বাবার মৃত্যু হয়েছে বলে অভিযোগ পাওয়া গেছে',\n",
              "  'আজ বুধবার দুপুরে গাজীপুর সিটি করপোরেশনের বাহাদুরপর এলাকায় এ ঘটনা ঘটে',\n",
              "  'নিহত ব্যক্তির নাম আসাদুল ইসলাম',\n",
              "  'তিনি গাইবান্ধার গোবিন্দগঞ্জ উপজেলার পাঁচউলিপুর এলাকার মৃত গোলাম উদ্দিনের ছেলে',\n",
              "  'নিহতের পরিবার ও পুলিশ সূত্র জানায় আসাদুল ইসলাম গাজীপুর সিটি করপোরেশনের বাহাদুরপুর তুলসীভিটা এলাকার ফিরোজের বাড়িতে সপরিবার ভাড়া থাকেন',\n",
              "  'সেখান থেকে স্থানীয় একটি পোশাক তৈরি কারখানায় চাকরি করতেন',\n",
              "  'আগস্ট বেলা টার দিকে তাঁর ছেলে মো নয়ন মিয়াকে  তুরাগ নদে মাছ ধরার কথা বলে বাড়ি থেকে ডেকে আঙ্গুটিয়াচালা এলাকায় নিয়ে যান প্রতিবেশী সেজু  আনন্দ  বাবলু মিয়া  শাহীন হোসেনসহ  কয়েকজন',\n",
              "  'সেখানে নৌকা থেকে নদে পড়ে নিখোঁজ হয় নয়ন',\n",
              "  'পরে সন্ধ্যায় তার লাশ ওই নদ থেকে উদ্ধার করেন স্থানীয় ব্যক্তিরা',\n",
              "  'এ ঘটনায় নৌকা থেকে নদে ফেলে দিয়ে নয়নকে হত্যা করা হয়েছে বলে দাবি করেন আসাদুল ইসলাম',\n",
              "  'বিষয়টি নিয়ে এলাকায় আসাদুলের ঘনিষ্ঠ সুজন মাহমুদ ও অভিযুক্তদের আত্মীয় আলমগীর হোসেনের সমর্থকদের মধ্যে বিরোধ সৃষ্টি হয়',\n",
              "  'এ নিয়ে গত সোমবার বিকেলে সালিস ডাকা হয়',\n",
              "  'প্রতিপক্ষের লোকজন উপস্থিত না থাকায় বৈঠকটি হয়নি',\n",
              "  'পরবর্তী সালিস বৈঠকের দিন বুধবার বেলা তিনটার দিকে নির্ধারণ করা হয়',\n",
              "  'সালিস বৈঠককে কেন্দ্র করে আসাদুল ইসলামকে স্থানীয় আলমগীর হোসেন তাঁর বাড়ির উঠানে ডেকে নিয়ে যান',\n",
              "  'সেখানে আলমগীর মোজাম্মেল ব্যাপারী হবি ব্যাপারীসহ তাঁদের লোকজনের সঙ্গে আসাদুলের বাগ্বিতণ্ডা হয়',\n",
              "  'একপর্যায়ে তাঁরা তাঁকে ব্যাপক মারধর করেন',\n",
              "  'এতে আহত হয়ে তিনি মাটিতে লুটিয়ে পড়েন',\n",
              "  'উদ্ধার করে স্থানীয় ক্লিনিকে নিয়ে গেলে আসাদুলকে মৃত ঘোষণা করেন কর্তব্যরত চিকিৎসক',\n",
              "  'খবর পেয়ে পুলিশ নিহতের লাশ উদ্ধার করে গাজীপুর শহীদ তাজউদ্দীন আহমদ মেডিকেল কলেজের মর্গে পাঠিয়েছে',\n",
              "  'গাজীপুর সিটির নং ওয়ার্ড কাউন্সিলর মো মোশারফ হোসেন বলেন আসাদুল তার ছেলের মৃত্যুর জন্য বিচার চেয়ে আসছিল বলে শুনেছি',\n",
              "  'সেই ঘটনাকে কেন্দ্রকে আসাদুলকেও মারধর করা হয়েছে',\n",
              "  'পুলিশ ঘটনাটি তদন্ত করছে',\n",
              "  'গাজীপুর মেট্রোপলিটন পুলিশের সদর থানার উপপরিদর্শক এসআই সৈয়দ বায়েজিদ জানান নিহতের চোখের পাশে ও শরীরের বিভিন্ন স্থানে জখমের চিহ্ন রয়েছে',\n",
              "  'এ ব্যাপারে আইনগত ব্যবস্থা গ্রহণ প্রক্রিয়াধীন'],\n",
              " ['কুষ্টিয়া সদর উপজেলায় শেখ রাসেল কুষ্টিয়াহরিপুর সংযোগ সেতু রক্ষা ব্লক বাঁধের ধসে পড়া অংশ থেকে আবারও ভাঙন শুরু হয়েছে',\n",
              "  'বুধবার সন্ধ্যা সাতটা থেকে এই ভাঙন দেখা দেয়',\n",
              "  'রাত সাড়ে আটটায় এ প্রতিবেদন লেখার সময় দুটি বাড়ি নদে বিলীন হয়ে গেছে',\n",
              "  'নদতীরবর্তী বাসিন্দারা তাদের বাড়ির অংশ খুলে ও মালামাল দ্রুত অন্যত্র সরিয়ে নিচ্ছে',\n",
              "  'এর আগে রোববার ভোর সাড়ে পাঁচটার দিকে হাটশ হরিপুর এলাকায় বাঁধের প্রায়  মিটার ব্লক গড়াই নদে বিলীন হয়',\n",
              "  'ধসে পড়া বাঁধের পাশেই গ্রামের মানুষের বসতি',\n",
              "  'ব্লক ধসে পড়ায় একটি বাড়ির কিছু অংশ ভেঙে পড়ে',\n",
              "  'গত তিন দিনে পানি আরও বেড়েছে',\n",
              "  'বাঁধের কয়েক মিটার পাশে থাকা বাড়ির দিকে পানি চলে যাচ্ছে',\n",
              "  'এতে ঝুঁকিতে আছে বাড়িঘরগুলো',\n",
              "  'নদতীরবর্তী বাসিন্দারা আতঙ্কে দিন কাটাচ্ছে',\n",
              "  'বুধবার বিকেলের পর সেখানে বালুভর্তি জিও ব্যাগ ফেলা হয়',\n",
              "  'পানি উন্নয়ন বোর্ডের তত্ত্বাবধানে অন্তত  হাজার  বস্তা ফেলা হয়',\n",
              "  'কিন্তু তাতে কোনো কাজ হয়নি',\n",
              "  'হঠাৎ করে সন্ধ্যা সাতটার দিকে সেখানে পানির নিচ থেকে বুদ্বুদ উঠতে থাকে',\n",
              "  'একপর্যায়ে ব্লক বাঁধ ভাঙতে থাকে',\n",
              "  'এ সময় তীরবর্তী বাসিন্দাদের মধ্যে আতঙ্ক ছড়িয়ে পড়ে',\n",
              "  'পাকা দালানের বাসিন্দারা রাতের আঁধারের মধ্যে দ্রুত তাদের আসবাব অন্যত্র সরাতে শুরু করে',\n",
              "  'রাত সাড়ে সাতটার পর সামসুল হক নামের এক ব্যক্তির একটি বাড়ি ভেঙে তলিয়ে যায়',\n",
              "  'এরপর রাত আটটার দিকে পাশেই মোজাম্মেল হকের পাকা বাড়ির কিছু অংশ ভেঙে তলিয়ে যায়',\n",
              "  'সাড়ে আটটা পর্যন্ত ব্লক বাঁধ ভেঙে সেতুর দিকে এগিয়ে আসতে থাকে',\n",
              "  'সন্ধ্যার পর থেকে দেড় ঘণ্টায় অন্তত  মিটার ভেঙেছে',\n",
              "  'ভাঙন সেতুর কাছাকাছি চলে যাচ্ছে',\n",
              "  'ভাঙনস্থল থেকে মাত্র এক শ মিটার দূরে একটি সরকারি প্রাথমিক বিদ্যালয় ও ওই সেতুর অবস্থান',\n",
              "  'ঘটনাস্থলে দাঁড়িয়ে হাটশ হরিপুর ইউনিয়ন পরিষদের ইউপি চেয়ারম্যান এম সম্পা মাহমুদ প্রথম আলোকে বলেন ভেঙে পড়া অংশে বালুর বস্তা ফেলা হয়েছে',\n",
              "  'কিন্তু পানির স্রোত তীব্র হওয়ায় ভাঙন ঠেকানো যাচ্ছে না',\n",
              "  'শুধু চেয়ে চেয়ে দেখছি',\n",
              "  'প্রকৃতির কাছে হার মানতে হচ্ছে',\n",
              "  'তবে স্থানীয় বাসিন্দাদের অভিযোগ প্রথম দিনের ভাঙনের পর যদি দ্রুত বাঁধ প্রতিরোধক গড়া যেত তাহলে সন্ধ্যার ঘটনা নাও ঘটতে পারত',\n",
              "  'এখানে প্রশাসনের গাফিলতি আছে বলে স্থানীয় ব্যক্তিরা জানান',\n",
              "  'কুষ্টিয়া পানি উন্নয়ন বোর্ডের উপসহকারী প্রকৌশলী মোস্তাফিজুর রহমান বলেন সোমবার কিছু বস্তা ফেলা হয়েছিল',\n",
              "  'মঙ্গলবার বিকেলেও ফেলা হয়েছে',\n",
              "  'জেলা প্রশাসক মোহাম্মদ সাইদুল ইসলাম বলেন সদর উপজেলা নির্বাহী কর্মকর্তা ইউএনও সাধন কুমার বিশ্বাসকে ঘটনাস্থলে পাঠানো হয়েছে',\n",
              "  'দ্রুত ব্যবস্থা নিতে বলা হয়েছে'],\n",
              " ['বিএনপির মহাসচিব মির্জা ফখরুল ইসলাম আলমগীর বলেছেন আওয়ামী লীগ সরকার একটি তাঁবেদার জনবিচ্ছিন্ন পুতুল সরকার',\n",
              "  'তারা মিথ্যা দিয়ে নিজেদের প্রতিষ্ঠিত করতে চায়',\n",
              "  'রাজনৈতিক প্রতিহিংসায় এই সরকার মুক্তিযুদ্ধের বিকৃত ইতিহাস প্রতিষ্ঠার বহুমুখী প্রচার চালাচ্ছে',\n",
              "  'এর বিরুদ্ধে বিএনপি ইতিহাস কথা কয় শিরোনামে সাংস্কৃতিক লড়াইয়ের সিদ্ধান্ত নিয়েছে',\n",
              "  'আজ বুধবার বিকেলে ইতিহাস কথা কয় শীর্ষক শিরোনামে এক ভার্চ্যুয়াল আলোচনা সভায় সভাপতির বক্তব্যে মির্জা ফখরুল ইসলাম এসব কথা বলেন',\n",
              "  'মির্জা ফখরুল বলেন সত্য কথাটা উঠে আসুক এ জন্য আজকে আমরা ইতিহাস কথা কয় বলে এই অনুষ্ঠান করছি',\n",
              "  'যত দিন বিকৃতির তৎপরতা চলবে তত দিনই এই লড়াই চলবে',\n",
              "  'যখন ইতিহাসের ঘটনাকে তারা দলীয় বয়ানে প্রতিষ্ঠায় লিপ্ত হবে তখনই ইতিহাস বিকৃতির বিরুদ্ধে চ্যালেঞ্জ নিয়ে হাজির হবে ইতিহাস কথা কয়',\n",
              "  'মির্জা ফখরুল বলেন শহীদ প্রেসিডেন্ট জিয়াউর রহমান সম্পর্কে মিথ্যা কথা বললে কেউ বিশ্বাস করবে না',\n",
              "  'কারণ জিয়াউর রহমান শুধু স্বাধীনতার ঘোষণাই দেননি তিনি পরে যখন দায়িত্ব পেয়েছেন তাঁর কর্মকাণ্ডের মধ্য দিয়ে এই দেশের মানুষের হৃদয়ে স্থান করে নিয়েছেন',\n",
              "  'তিনি চির ভাস্কর হয়ে আছেন',\n",
              "  'পঁচাত্তরের ঘটনার সঙ্গে জিয়াউর রহমানকে জড়িয়ে আইনমন্ত্রী আনিসুল হকের দেওয়া বক্তব্যকে মিথ্যা ভিত্তিহীন ও রাজনৈতিক দুরভিসন্ধিমূলক অপপ্রচার বলে মন্তব্য করেন মির্জা ফখরুল',\n",
              "  'তিনি বলেন আইনমন্ত্রীর বক্তব্য  সালের  আগস্টের হত্যা মামলার রায়কেও অবশ্যই প্রশ্নবিদ্ধ করছে',\n",
              "  'কারণ সুদীর্ঘ বিচারপ্রক্রিয়ায় সাক্ষীসাক্ষ্য পর্যালোচনা করে ক্ষমতাসীনেরাই বিচারকার্য সম্পন্ন করেছে',\n",
              "  'এখন নতুন করে  আগস্টের হত্যাকাণ্ড সম্পর্কে পাস্ট অ্যান্ড ক্লোজ চ্যাপটারকে পুনরায় বিতর্কের বিষয় হিসেবে তুলে এনে আইনমন্ত্রী জ্ঞানপাপীর পরিচয় দিচ্ছেন',\n",
              "  'প্রকৃত ইতিহাস তুলে ধরলে আওয়ামী লীগ ভয় পায়দলের স্থায়ী কমিটির সদস্য খন্দকার মোশাররফ হোসেন অভিযোগ করেন প্রকৃত ইতিহাস তুলে ধরলে আওয়ামী লীগ ভয় পায়',\n",
              "  'তিনি ক্ষমতাসীনদের কাছে প্রশ্ন করেন বাংলাদেশের মৌলিক প্রশ্নে মুক্তিযুদ্ধ থেকে শুরু করে দেশের উন্নয়ন দেশকে স্বনির্ভর করা দেশকে সম্মানজনক অবস্থানে নেওয়া মাথা উঁচু করে দাঁড়ানোর জন্য দেশকে প্রস্তুত করাএসব কারা করেছে',\n",
              "  'সবগুলোতেই শহীদ প্রেসিডেন্ট জিয়াউর রহমান বিএনপি ও খালেদা জিয়ার সফলতা',\n",
              "  'সে জন্যই তারা সত্য ইতিহাসকে ধামাচাপা দেওয়ার জন্য জনগণকে বিভ্রান্ত করার জন্য এই প্রজন্মকে বিভ্রান্ত করার জন্য ইতিহাসকে বিকৃতি করছে',\n",
              "  'আফগানিস্তান থেকে শিক্ষা নিতে হবেবিএনপির ভাইস চেয়ারম্যান অবসরপ্রাপ্ত মেজর হাফিজ উদ্দিন আহম্মদ বলেন স্বাধীনতার ঘোষণা তো একজন রাজনৈতিক নেতার মুখ থেকেই আমরা আশা করেছিলাম',\n",
              "  'তিনি বা তারা দিতে পারেনি দিয়েছেন এক অখ্যাত মেজর জিয়াউর রহমান',\n",
              "  'আমরা যেটা পারিনি তুমি পারতে গেলে কেন',\n",
              "  'এই হীনম্মন্যতা থেকে তারা ইতিহাস বিকৃত করছে  সাল থেকেই',\n",
              "  'ক্ষমতাসীনদের উদ্দেশে হাফিজ উদ্দিন আহম্মদ বলেন এই যে লাখো মানুষ জীবন দিল একটি আধুনিক সেনাবাহিনীর বিরুদ্ধে জীবন পণ করে বিজয় ছিনিয়ে নিল এই কৃতিত্ব কাউকে দিতে চায় না তারা',\n",
              "  'হাফিজ উদ্দিন আহম্মদ বলেন আমি বলব এখনো সময় আছে শিক্ষা নেওয়ার',\n",
              "  'আফগানিস্তানে কী হয়েছেএটা থেকে শিক্ষা নেওয়ার চেষ্টা করেন',\n",
              "  'অনেককে কিন্তু হেলিকপ্টারের ডানা ধরে ঝুলতে হবে',\n",
              "  'আফগানিস্তান থেকে আমরা কি শিক্ষা নিতে পারছি যে জনগণের জয় একদিন না একদিন হবেই',\n",
              "  'দেশের অধিকাংশ জনগণ যাকে সমর্থন করবে যে দল বা যে আদর্শকে সমর্থন করবে এটিকে কোনো দিন দাবিয়ে রাখা যায় না',\n",
              "  'যার জন্য পৃথিবী সবচেয়ে সর্বশক্তিমান পরাশক্তিকেও আফগানিস্তান থেকে যেতে হয়েছে',\n",
              "  'ইতিহাস কথা কয় শীর্ষক আলোচনা সভায় প্রধান অতিথির বক্তব্য দেন বিএনপির ভারপ্রাপ্ত চেয়ারম্যান তারেক রহমান',\n",
              "  'দলের প্রচার সম্পাদক শহিদ উদ্দিন চৌধুরীর সঞ্চালনায় সভায় আরও বক্তব্য দেন কল্যাণ পার্টির চেয়ারম্যান সৈয়দ মুহাম্মদ ইবরাহিম বিএনপির স্থায়ী কমিটির সদস্য মির্জা আব্বাস গয়েশ্বর চন্দ্র রায় আবদুল মঈন খান নজরুল ইসলাম খান সেলিমা রহমান ইকবাল হাসান মাহমুদ প্রমুখ'],\n",
              " ['কিশোরগঞ্জের পাকুন্দিয়ায় ব্রহ্মপুত্র নদে নৌকাডুবিতে নিখোঁজ স্নাতক শিক্ষার্থী মোবারক হোসেনের  লাশ উদ্ধার করা হয়েছে',\n",
              "  'আজ বুধবার সন্ধ্যা সাতটার দিকে উপজেলার চরফরাদী ইউনিয়নের দক্ষিণ চরটেকী এলাকার ব্রহ্মপুত্র নদে তাঁর লাশ ভেসে ওঠে',\n",
              "  'পরে এলাকাবাসী লাশটি উদ্ধার করেন',\n",
              "  'নিহত মোবারক হোসেন উপজেলার চরফরাদী ইউনিয়নের চরপাড়াতলা গ্রামের মো বকুল মিয়ার ছেলে ও পাকুন্দিয়া সরকারি কলেজের স্নাতক প্রথম বর্ষের শিক্ষার্থী',\n",
              "  'গতকাল মঙ্গলবার দুপুর সাড়ে টার দিকে নৌকাডুবির ঘটনায় তিনি নিখোঁজ হন',\n",
              "  'ওই দিন সন্ধ্যা পর্যন্ত ফায়ার সার্ভিসের ডুবুরি দল ঘটনাস্থলে উদ্ধার তৎপরতা চালালেও তাঁর সন্ধান পাওয়া যায়নি',\n",
              "  'পুলিশ ও স্থানীয় সূত্র জানায় মোবারক তাঁর দুই বন্ধু সম্রাট ও জাকির হোসেনকে নিয়ে ময়মনসিংহের পাগলা এলাকায় যাওয়ার জন্য বাড়ি থেকে বের হয়েছিলেন',\n",
              "  'পথে ব্রহ্মপুত্র নদ পার হওয়ার সময় তাঁদের বহনকারী নৌকাটি ডুবে যায়',\n",
              "  'এ সময় মোবারকের দুই বন্ধু সম্রাট ও জাকির এবং নৌকার মালিক ফারুক মিয়া সাঁতরে তীরে উঠতে সক্ষম হলেও মোবারক নদের পানিতে তলিয়ে গিয়ে নিখোঁজ হন',\n",
              "  'পাকুন্দিয়া থানার ভারপ্রাপ্ত কর্মকর্তা ওসি মো সারোয়ার জাহান জানান বুধবার সন্ধ্যা সাতটার দিকে ঘটনাস্থল থেকে প্রায় এক কিলোমিটার দূরে নিখোঁজ মোবারক হোসেনের লাশ ভেসে ওঠে',\n",
              "  'এ সময় এলাকাবাসীর সহযোগিতায় তাঁর লাশ উদ্ধার করা হয়'],\n",
              " ['বঙ্গবন্ধু শেখ মুজিবুর রহমানকে কাছে থেকে দেখেছেন তাঁরা সবাই',\n",
              "  'কেউ ছিলেন বঙ্গবন্ধুর মন্ত্রিসভার সদস্য',\n",
              "  'বঙ্গবন্ধুর নির্দেশে গঠিত পরিকল্পনা কমিশনের সদস্যরাও ছিলেন',\n",
              "  'যে পরিকল্পনায় রচিত হয়েছিল দেশের অর্থনীতির ভিত',\n",
              "  'বঙ্গবন্ধুর প্রশাসনের কর্মকর্তারাও ছিলেন',\n",
              "  'আবার ভিন্ন রাজনৈতিক দলের হয়েও বঙ্গবন্ধুর স্নেহধন্য হয়েছিলেন তাঁরাও ছিলেন',\n",
              "  'বঙ্গবন্ধুর জন্মশতবার্ষিকীর এ পর্বে বাংলাদেশের মুক্তিযুদ্ধের সুবর্ণজয়ন্তীর এই সময়ে তাঁরা শোনালেন জাতির জনকের সঙ্গে তাঁদের সম্পর্কের নানা অজানা কথা',\n",
              "  'নতুন প্রজন্মের কাছে হয়তো তা হয়ে থাকবে এক অনন্য কথ্য দলিল হিসেবে',\n",
              "  'এ আলোচনার আয়োজন হলো আজ বুধবার',\n",
              "  'বাংলাদেশ উন্নয়ন গবেষণা প্রতিষ্ঠান বিআইডিএস বঙ্গবন্ধুকে কাছে থেকে দেখা শীর্ষক এই ভার্চ্যুয়াল অনুষ্ঠানের আয়োজন করেছিল',\n",
              "  'যে মাসে এই আলোচনা হলো সেই আগস্টের  তারিখে এ সপরিবার নিহত হয়েছিলেন ক্ষণজন্মা এই মহান পুরুষ',\n",
              "  'তাঁর সাহচর্য পাওয়া ব্যক্তিরা শোনালেন শেখ মুজিবুর রহমান থেকে বঙ্গবন্ধু এবং এরপর জাতির জনক হয়ে ওঠার আখ্যান',\n",
              "  'মাসের রক্তঝরা যুদ্ধের পর বিধ্বস্ত বাংলাদেশ',\n",
              "  'বঙ্গবন্ধু পাকিস্তানের কারাগার থেকে দেশে ফিরে এসেছেন',\n",
              "  'এসেই খোঁজ করেছিলেন পরে তাঁরই নির্দেশে গঠিত পরিকল্পনা কমিশনের ডেপুটি চেয়ারম্যান অর্থনীতিবিদ নুরুল ইসলামকে',\n",
              "  'তিনি আজ যুক্তরাষ্ট্র থেকে ধারণ করা ভিডিও বক্তব্যে সেই কথা জানালেন',\n",
              "  'বললেন  সালের  জানুয়ারি দেশে ফিরেই শুরু হয় দেশ গঠনে বঙ্গবন্ধুর তৎপরতা',\n",
              "  'এই কমিশন গঠনের ইতিবৃত্ত এর দুর্ভিক্ষ বৈদেশিক নীতি বাকশাল গঠনএসব নানা বিষয় নিয়ে কথা বললেন প্রতিথযশা অর্থনীতিবিদ নুরুল ইসলাম',\n",
              "  'বঙ্গবন্ধুর অপার দেশপ্রেম অসম সাহস ও রাজনৈতিক প্রজ্ঞার নানা বর্ণনা উঠে এল তাঁর কথায়',\n",
              "  'বললেন বঙ্গবন্ধু আমাকে অসম্ভব বিশ্বাস করতেন',\n",
              "  'আমার ব্যক্তিত্ব ও সক্ষমতার ওপরে তাঁর আস্থা ছিল',\n",
              "  'অর্থনীতিবিদ নুরুল ইসলাম বলেন  সালের দুর্ভিক্ষের সময় বঙ্গবন্ধুকে বলেছিলাম খাদ্যশস্যের অভাব আছে',\n",
              "  'যা আছে আমাদের সমানভাগে ভাগ করে খেতে হবে',\n",
              "  'মজুতদারদের বলেন মজুত বন্ধ করতে',\n",
              "  'বঙ্গবন্ধু সেই সময় বলেছেন দেশে খাদ্যের অভাব দেখা দিলে সরকারের বৈধতা নিয়ে প্রশ্ন উঠতে শুরু করে',\n",
              "  'ইতিহাস সেই সরকারকেই দায়ী করে',\n",
              "  'খাদ্যের অভাব দেখা দিলে বিপ্লব শুরু হয়ে যেতে পারে',\n",
              "  'বাকশাল গঠন নিয়ে বঙ্গবন্ধুর সঙ্গে তাঁর আলাপচারিতা নিয়ে নুরুল ইসলাম বলেন আমরা বঙ্গবন্ধুকে বলেছিলাম আপনি সারা জীবন গণতন্ত্রের জন্য লড়াই করেছেন',\n",
              "  'আপনি কেন বাকশাল করলেন',\n",
              "  'জবাবে বঙ্গবন্ধু বলেছিলেন আমি ঝুঁকি নিচ্ছি',\n",
              "  'কিন্তু আমার উপায় নেই',\n",
              "  'আমি জানি আমি সফল হব',\n",
              "  'দেশের প্রথম পরিকল্পনা কমিশনের সদস্য ছিলেন অর্থনীতিবিদ রেহমান সোবহান',\n",
              "  'তাঁর কাছে বঙ্গবন্ধু এক অনন্য চরিত্র',\n",
              "  'বাংলাদেশের অর্থনীতির প্রারম্ভিক এই রূপকার বললেন অনেক নামজাদা পরিকল্পনাবিদের চেয়ে পরিকল্পনায় দক্ষ ছিলেন বঙ্গবন্ধু',\n",
              "  'মানুষকে কথা দিয়ে কথা রাখা বঙ্গবন্ধুর চরিত্রের সবচেয়ে বড় বৈশিষ্ট্য ছিলএ কথাও স্মরণ করেন রেহমান সোবহান',\n",
              "  'বলেন বঙ্গবন্ধু যে কথা মানুষকে বলতেন তা রাখতেন',\n",
              "  'অনেক রাজনীতিক আছেন যাঁরা রাজনীতির মাঠে নানা বাগাড়ম্বর রেটোরিক করেন',\n",
              "  'কিন্তু ঘরে গিয়ে সেসব কথা ভুলে যান',\n",
              "  'কিন্তু বঙ্গবন্ধু এমন একটি কথাও বলতেন না যা তিনি বাস্তবায়ন করতে পারবেন না',\n",
              "  'অধ্যাপক রেহমান সোবহান বলেন বঙ্গবন্ধু কমিউনিস্ট ছিলেন না',\n",
              "  'কিন্তু সমাজতন্ত্রের প্রতি তাঁর আস্থা ছিল',\n",
              "  'তিনি বিশ্বাস করতেন সামাজিক ন্যায়বিচারে',\n",
              "  'তিনি সমতাভিত্তিক সমাজের স্বপ্ন দেখতেন',\n",
              "  'যেখানে থাকবে না বৈষম্য',\n",
              "  'সেই ছয় দফা দাবি জীবনাচরণের প্রতিটি পর্যায়ে বৈষম্যের বিরুদ্ধে বঙ্গবন্ধুর লড়াই ছিল',\n",
              "  'তাঁর অসমাপ্ত আত্মজীবনীতে দেখা গেছে বৈষম্যের বিরুদ্ধে মানুষের মঙ্গলের জন্য কী আকুতি ছিল তাঁর',\n",
              "  'তিনি মানুষের বিপুল ভালোবাসা পেয়েছিলেন',\n",
              "  'তাঁর প্রতি মানুষের এই ভালোবাসার কারণ বঙ্গবন্ধু নিজের জীবন থেকে মানুষের কাছে থাকার শিক্ষা ও পাঠ নিয়েছিলেন',\n",
              "  'আর আমৃত্যু মানুষের পক্ষে থেকেছেন',\n",
              "  'শোষণমুক্ত সমাজসেটাই ছিল বঙ্গবন্ধুর বড় স্বপ্ন',\n",
              "  'সারা জীবন বৈষম্যের বিরুদ্ধে বঙ্গবন্ধুর এই লড়াইয়ের কথা স্মরণ করেন তাঁর মন্ত্রিসভার সদস্য এবং স্বাধীন বাংলাদেশের প্রথম সংবিধানের অন্যতম রচয়িতা ড কামাল হোসেন',\n",
              "  'তিনি বললেন আজ মুক্তিযুদ্ধের  বছর পরও বঙ্গবন্ধুর সেই স্বপ্নের সঠিক বাস্তবায়ন আমরা করতে পারিনি',\n",
              "  'বৈষম্য বরং দিন দিন বাড়ছে',\n",
              "  'দেশের বর্তমান গণতান্ত্রিক ব্যবস্থা ও অর্থনীতির নানা দিক নিয়ে কথা বলেন কামাল হোসেন',\n",
              "  'বলেন এখন টাকার কাছে দেশের জনগণ ক্ষমতা হারিয়েছে',\n",
              "  'পুঁজি পাচার হচ্ছে',\n",
              "  'কিন্তু আমাদের মুক্তিযুদ্ধের মূল বিষয় ছিল মানুষের মুক্তি বৈষম্য দূর করা',\n",
              "  'আমাদের সংবিধানেও সে কথাই বিধৃত আছে',\n",
              "  'এখন আমাদের জাতীয়ভাবে ঐক্যবদ্ধ হতে হবে',\n",
              "  'রাজনৈতিক যে মতপার্থক্য থাকুক রাষ্ট্রের গুরুত্বপূর্ণ ইস্যুতে কেন আমরা ঐক্যবদ্ধ হতে পারছি না',\n",
              "  'দেশে কার্যকর ও অর্থপূর্ণ গণতন্ত্রের জন্য আমাদের এক হতে হবে',\n",
              "  'বহুদলীয় গণতন্ত্রের জন্য এটা দরকার',\n",
              "  'ড কামাল হোসেনের কথা বঙ্গবন্ধু শুধু দেশে নন সারা বিশ্বে তিনি সম্মানিত',\n",
              "  'তিনি এক অসম্ভবকে সম্ভব করেছিলেন বাংলাদেশের স্বাধীনতা এনেছিলেন',\n",
              "  'বিংশ শতাব্দীর সবচেয়ে বড় ঘটনা বাংলাদেশের অভ্যুদয়',\n",
              "  'সেই বিজয় অর্জিত হয়েছিল বঙ্গবন্ধুর নেতৃত্বেই',\n",
              "  'বাংলাদেশ ব্যাংকের সাবেক গভর্নর মোহাম্মদ ফরাসউদ্দিন ছিলেন বঙ্গবন্ধুর একান্ত সচিব',\n",
              "  'বঙ্গবন্ধু পরিবারের সদস্যদের সঙ্গেও ছিল তাঁর সম্পর্ক',\n",
              "  'সালের সেই কালরাত্রির আগেও দেখেছেন বঙ্গবন্ধুকে',\n",
              "  'বললেন বঙ্গবন্ধু আমাদের এ দেশের মানুষকে একটি ঠিকানা দিয়েছিলেন রাষ্ট্র দিয়েছিলেন',\n",
              "  'দুষ্কৃতকারীদের কাছে বঙ্গবন্ধু ক্ষয় হবেন কিন্তু বাংলাদেশের আপামর মানুষের কাছে জাতির পিতার স্মৃতি অমর অক্ষয়',\n",
              "  'ফরাসউদ্দিন বলেন মানুষের প্রতি তাঁর ভালোবাসা ছিল প্রবাদতুল্য',\n",
              "  'তিনি প্রকৃত অর্থেই ছিলেন জাতির পিতা',\n",
              "  'রাজনীতিতে যাঁরা তাঁর প্রতিপক্ষ ছিলেন তাঁদের বিপদে সহায়তা করতে কখনো দ্বিধা করতেন না',\n",
              "  'কাছের মানুষদের চেয়ে রাজনৈতিক বৈরী যারা তাদের প্রতি বঙ্গবন্ধু বেশি দৃষ্টি দিতেন',\n",
              "  'সময়ে পরিকল্পনা মন্ত্রণালয়ের সচিব পরিকল্পনা কমিশনের সচিব এক্সটার্নাল রিসোর্স বিভাগের প্রদান হিসেবে দায়িত্ব পালন করেছেন এম সায়েদুজ্জামান',\n",
              "  'বঙ্গবন্ধুর দূরদর্শিতা দেশপ্রেম সহমর্মিতার নানা দিক তুলে ধরেন এম সায়েদুজ্জামান',\n",
              "  'স্মৃতিচারণা করে এম সায়েদুজ্জামান বলেন একদিন দুটি ফাইল নিয়ে রুহুল কুদ্দুস আমাকে বললেন তুমি আমার সঙ্গে চলো বঙ্গবন্ধুর কাছে যাব',\n",
              "  'তখন নতুন গণভবনে গেলাম',\n",
              "  'প্রবেশের সময় পুলিশ গেটে আটকালো',\n",
              "  'আইডি দেখাতে হলো',\n",
              "  'কার্ড দেখাতে হলো সিকিউরিটি চেক করল',\n",
              "  'বঙ্গবন্ধুর কাছে গেলাম',\n",
              "  'এরপর কাজ হয়ে গেল',\n",
              "  'এরপর রুহুল কুদ্দুস বললেন বঙ্গবন্ধুকে একটা কথা আপনাকে বলতে চাই',\n",
              "  'তখন বঙ্গবন্ধু বললেন বলেন বলেন',\n",
              "  'আপনি এখানে সকালবেলা কাজ করতে আসেন সারা দিন এখানে কাজ করেন দুপুরে এখানে খান এখানেই বিশ্রাম নেন',\n",
              "  'আপনার চারদিকে আর্মড গার্ডস দুই থেকে তিন স্তর আপনাকে পাহারা দিচ্ছে',\n",
              "  'রাতের বেলায় আপনি যখন বাড়িতে যান তখন তো একটা পাখির বাসায় থাকেন',\n",
              "  'বিষয়টি চিন্তা করে দেখেন',\n",
              "  'বঙ্গবন্ধু রুহুল কুদ্দুসের পিঠে হাত দিয়ে বললেন সেটা চিন্তা করবেন না',\n",
              "  'বাংলাদেশের কেউ আমার গায়ে হাত দেবে না',\n",
              "  'এই বলে তিনি চলে গেলেন',\n",
              "  'বঙ্গবন্ধু  সালের  জানুয়ারি দেশে ফিরে এলেন',\n",
              "  'জানুয়ারি প্রধানমন্ত্রী হলেন',\n",
              "  'জানুয়ারি প্রতিমন্ত্রীর মর্যাদায় তাঁর রাজনৈতিক সচিব হন তোফায়েল আহমেদ',\n",
              "  'জ্যেষ্ঠ এই আওয়ামী লীগ নেতা বঙ্গবন্ধুর সাহচর্যে এসেছিলেন দীর্ঘ সময় ধরে',\n",
              "  'সাবেক মন্ত্রী তোফায়েল আহমেদ বললেন বঙ্গবন্ধুর দরদি চরিত্রের কথা',\n",
              "  'জানান বিভিন্ন মানুষকে সহযোগিতার জন্য একটি তহবিল তিনিই দেখভাল করতেন',\n",
              "  'সেখান থেকে রাজনৈতিক বিরুদ্ধবাদী এমনকি তাঁদের পরিবারেরও সহযোগিতা মিলত',\n",
              "  'মাওলানা আবদুল হামিদ খান ভাসানীর সঙ্গে বঙ্গবন্ধুর রাজনৈতিক দূরত্ব ছিল',\n",
              "  'কিন্তু তিনি অত্যন্ত শ্রদ্ধা করতেন এবং নানাভাবে তাঁকে সহায়তা করতেন',\n",
              "  'আর যেকোনো মানুষকে অর্থ দিয়ে তাঁদের নাম লিখে রাখতেন তোফায়েল আহমেদ',\n",
              "  'বঙ্গবন্ধু এই তালিকা দেখে একবার তাঁকে বলেন এভাবে পুরো নাম লিখে রেখেছ কেন',\n",
              "  'নামের আদ্যক্ষর লিখে রাখবে',\n",
              "  'তোফায়েল আহমেদ বলেন যে হাতে সহায়তা দেবেন অন্য হাত যেন না জানতে পারে এমন মনোবৃত্তির মানুষ ছিলেন বঙ্গবন্ধু',\n",
              "  'অনেক মানুষকে নীরবে উপকার করে গেছেন কিন্তু তা কাউকে জানতেও দেননি',\n",
              "  'বঙ্গবন্ধুর রাজনৈতিক দল আওয়ামী লীগ বা এর ছাত্রসংগঠন ছাত্রলীগ কখনই করেননি মুজাহিদুল ইসলাম সেলিম',\n",
              "  'এখনো তিনি রয়ে গেছেন বাম আদর্শের ঝান্ডা নিয়ে',\n",
              "  'এখন বাংলাদেশের কমিউনিস্ট পার্টির সিপিবি সভাপতি মুজাহিদুল ইসলাম সেলিম বঙ্গবন্ধুর সময় ঢাকা বিশ্ববিদ্যালয় কেন্দ্রীয় ছাত্র সংসদের ডাকসু ভিপি ছিলেন',\n",
              "  'জানালেন তিনি অনেকবার বঙ্গভবনে গেছেন',\n",
              "  'স্মৃতিতে ভর করে সেলিম বলেন তাক লাগিয়ে দেওয়ার মতো একটা সম্মেলন ছিল  সালে',\n",
              "  'ছাত্র ইউনিয়নের সেই সম্মেলনে আমরা জাতীয় নেতৃবৃন্দকে আমন্ত্রণ জানিয়েছিলাম',\n",
              "  'বঙ্গবন্ধুও এসেছিলেন',\n",
              "  'সেই সম্মেলনে আমি প্রেসিডেন্ট নির্বাচিত হই',\n",
              "  'সেখানে পতাকা উত্তোলনের পর আমি স্লোগান দিলাম জনগণের মৌলিক অধিকার রক্ষার পক্ষে সাম্রাজ্যবাদের বিরুদ্ধে',\n",
              "  'সব কটি স্লোগান দেওয়ার পর যখন থেমে যাচ্ছি তখন বঙ্গবন্ধু আমাকে কানেকানে বললেন সেলিম একটু জয় বাংলা স্লোগানটাও দাও',\n",
              "  'মনে রাইখো সাম্প্রদায়িকতা কিন্তু বড় বিপদ',\n",
              "  'এখান থেকে বের হয়ে আসতে হবে',\n",
              "  'তাঁর পরামর্শমতো সব স্লোগানের পরে জয় বাংলা স্লোগানটিও দিয়েছিলাম',\n",
              "  'মুজাহিদুল ইসলাম সেলিম বলেন বঙ্গবন্ধু ইতিহাসের মহানায়ক',\n",
              "  'বঙ্গবন্ধুর প্রতি শ্রদ্ধা নিবেদন করতে হলে বঙ্গবন্ধুকে জানতে হবে ভালো করে',\n",
              "  'সেই জানাটায় আমাদের আরও গুরুত্ব দেওয়া প্রয়োজন',\n",
              "  'তাঁর চেয়েও গুরুত্বপূর্ণ কথা হলো ব্যক্তি হিসেবে বঙ্গবন্ধুকে জানলে হবে না তাঁর নীতিআদর্শকে জানতে হবে এবং উপলব্ধি করতে হবে',\n",
              "  'সেই উপলব্ধির ভিত্তিতে তাঁর প্রতি আমাদের শ্রদ্ধা ও ভালোবাসা নিবেদন করতে হবে',\n",
              "  'জীবনে একবার বঙ্গবন্ধুকে কাছ থেকে দেখার ও কথা বলার সুযোগ হয়েছিল পরিকল্পনামন্ত্রী এম এ মান্নানের',\n",
              "  'সেদিনের স্মৃতিচারণা করে এম এ মান্নান বলেন পাকিস্তানের শেষের দিকে আমি একটা পরীক্ষায় পাস করেছিলাম',\n",
              "  'নতুন বাংলাদেশ সরকারের অনেকে আমাদেরকে চাকরি না দেওয়ার পক্ষে মত ছিল',\n",
              "  'পাস করা সেই চাকরিপ্রার্থীদের পক্ষে আমাকে পাঠানো হয়েছিল বঙ্গবন্ধুর কাছে বিষয়টি তুলে ধরার জন্য',\n",
              "  'খুব সম্ভব  সালের জানুয়ারির কোনো একদিন রাত টার পর দেখা করার সুযোগ এল',\n",
              "  'সিঁড়ি বেয়ে উঠে কক্ষে প্রবেশ করতেই বঙ্গবন্ধু মাথা ঘুরিয়ে বললেন তুমি কে',\n",
              "  'তখন দুই কদম কাছে গিয়ে বললাম আমরা একটা পরীক্ষা দিয়েছিলাম',\n",
              "  'এখন আমাদেরকে চাকরিতে নেওয়া হবে না বলে চিন্তা চলছে',\n",
              "  'তিনি বললেন কী পরীক্ষা',\n",
              "  'আমি বললাম সেন্ট্রাল সুপিরিয়র সার্ভিস',\n",
              "  'তিনি বললেন ভালো পরীক্ষা',\n",
              "  'তোমাদেরকে আমার দরকার',\n",
              "  'সেখানে তোফায়েল আহমেদসহ আরও একজন উপস্থিত ছিলেন',\n",
              "  'সরল ভঙ্গিতে বঙ্গবন্ধু তোফায়েল আহমেদকে বললেন এদের বিষয়টা দেখো',\n",
              "  'এটা ছিল আমার বঙ্গবন্ধুকে সরাসরি দেখা ও কথা বলা',\n",
              "  'আজকের অনুষ্ঠান সঞ্চালনা করেন বিআইডিএসের মহাপরিচালক বিনায়ক সেন',\n",
              "  'তিনি বঙ্গবন্ধুর সমাজতন্ত্র নিয়ে ভবিষ্যতে আলোচনার ইচ্ছে পোষণ করেন',\n",
              "  'বিনায়ক সেন বলেন বঙ্গবন্ধুর সমাজতন্ত্রের পাঁচটি দিক আছে',\n",
              "  'একটি হচ্ছে জমিদার সমান্তবাদবিরোধিতা',\n",
              "  'দ্বিতীয়ত সাধারণ পুঁজিবাদবিরোধী তিনি ছিলেন না কিন্তু একচেটিয়া পুঁজিবাদের বিরোধী ছিলেন',\n",
              "  'পাকিস্তানের মতো  পরিবার বাংলাদেশে জন্মাক সেটা তিনি চাননি',\n",
              "  'তৃতীয় দিক হচ্ছে আমাদের সংবিধানে যেটা আছে যে সকল মানুষের জন্য অন্ন বস্ত্র বাসস্থান শিক্ষা স্বাস্থ্য পুষ্টিএই মৌলিক প্রয়োজনগুলোর ব্যবস্থা করা',\n",
              "  'সংবিধানের দশম ধারায় যেটা আছে যে আয় ও সম্পদ বণ্টনের যে বৈষম্য আছে সেটাকে কমিয়ে আনা',\n",
              "  'সহনীয় পর্যায়ে নামিয়ে আনা',\n",
              "  'পঞ্চমত সংবিধানের  নম্বর ধারায় আছে শ্রমিক কৃষক ও অনগ্রসর জনগণের ওপর যে অর্থনৈতিক ও অঅর্থনৈতিক শোষণ চলছে সেটার অবসান ঘটানো',\n",
              "  'বিনায়ক সেন বলেন জিন্নাহ নেহরু গান্ধীসবাই ছিলেন উচ্চশিক্ষিত',\n",
              "  'তাঁরা বিদেশে পড়াশোনা করেছেন',\n",
              "  'ধনী পরিবার থেকে এসেছেন',\n",
              "  'বঙ্গবন্ধু এসেছিলেন নিম্নমধ্যবিত্ত পরিবার থেকে',\n",
              "  'নিম্নমধ্যবিত্ত পরিবার থেকে এলেও সেই পরিবারে বোধের শক্তি ছিল বলে উল্লেখ করেন বিনায়ক সেন',\n",
              "  'তিনি বলেন একবার শেরেবাংলা এ কে ফজলুল হক সম্পর্কে রাজনৈতিক কারণে বঙ্গবন্ধু একটু বিরক্ত ছিলেন এবং সেটা প্রকাশ করেছিলেন',\n",
              "  'বঙ্গবন্ধুর বাবা তাঁকে ডেকে নিয়ে বললেন সবার সম্পর্কে সমালোচনা করবে সেটা ঠিক কিন্তু শেরেবাংলা সম্পর্কে বলার সময় একটু মনে রেখো বাংলার কৃষকদের জন্য তিনি অনেক কাজ করেছেন',\n",
              "  'নিম্নমধ্যবিত্ত পরিবার থেকে এলেও বঙ্গবন্ধুর পরিবারে প্রজ্ঞা ছিল',\n",
              "  'জ্ঞানের গরিমা ছিল না বোধের শক্তি ছিল',\n",
              "  'বঙ্গবন্ধুর মধ্যেও তাই'],\n",
              " ['সন্তানের মতো বড় করছিলেন টি বিদেশি জাতের ভেড়া',\n",
              "  'হতদরিদ্র নিসন্তান দম্পতির এগুলোই ছিল বেঁচে থাকার অবলম্বন',\n",
              "  'সেই সঙ্গে ছিল আয়ের প্রধান উৎস',\n",
              "  'স্বামীস্ত্রী মিলে সারাক্ষণ সেবাযত্ন করতেন ভেড়াগুলোকে',\n",
              "  'প্রাণিসম্পদ অধিদপ্তর থেকে কৃমিনাশক ওষুধ নিয়ে আজ বুধবার সেই ওষুধ খাওয়ানোর পর তাঁদের সেই ভেড়ার মধ্যে টি মারা গেছে',\n",
              "  'বাকি বেশ কয়েকটি অসুস্থ হয়ে পড়ে আছে',\n",
              "  'এই পরিস্থিতি ঝিনাইদহের কালীগঞ্জ উপজেলার কমলাপুর গ্রামের আফজাল হোসেন ও আরজিনা বেগম দম্পতির',\n",
              "  'তবে প্রাণিসম্পদ অধিদপ্তরের ভাষ্য কৃমির জন্য যথাযথ ওষুধ দেওয়া হয়েছে',\n",
              "  'এটা খাওয়ানোর পর ভেড়া মারা যাওয়ার কথা নয়',\n",
              "  'এরপরও কেন মারা গেল তা তারা অনুসন্ধান করছে',\n",
              "  'আফজাল হোসেন বলেন তিনি হতদরিদ্র মানুষ',\n",
              "  'নিজের কোনো চাষের জমি নেই',\n",
              "  'তিন শতক জমির ওপর টিনশেডের এক কক্ষের ঘরে বসবাস করেন',\n",
              "  'আর বাড়ির সঙ্গে থাকা  শতক জমির এক পাশে ভেড়ার খামার গড়ে তুলেছেন',\n",
              "  'গত পাঁচ বছর তিনি এই ভেড়াগুলো বড় করে তুলছেন',\n",
              "  'তিনি বলেন টি ভেড়া দিয়ে তিনি যাত্রা শুরু করেন',\n",
              "  'একে একে টি ভেড়া হয়েছে তাঁর',\n",
              "  'এর মধ্যে বড়গুলোর বাজারমূল্য  হাজার পর্যন্ত রয়েছে আর ছোটগুলো  থেকে  হাজার টাকায় বিক্রি হবে',\n",
              "  'তিনি এই পাঁচ বছরে প্রায়  লাখ টাকা ব্যয় করেছেন ভেড়াগুলোকে বড় করে তুলতে',\n",
              "  'আশা ছিল আর ছয় মাস পর এগুলো বিক্রি করে  লক্ষাধিক টাকা আয় করবেন',\n",
              "  'আফজাল হোসেন বলেন সম্প্রতি তিনি খেয়াল করেন ভেড়াগুলোর স্বাভাবিক পায়খানা হচ্ছে না',\n",
              "  'এ অবস্থায় গতকাল মঙ্গলবার সকালে তিনি কালীগঞ্জ উপজেলা প্রাণিসম্পদ অধিদপ্তরে যান',\n",
              "  'সেখানকার চিকিৎসকের সঙ্গে আলাপ করলে তাঁরা কৃমিনাশক ওষুধ দেন',\n",
              "  'সেই ওষুধ গর্ভবতী ভেড়াগুলোকে না খাওয়াতে বলে দেন চিকিৎসক',\n",
              "  'এক প্যাকেট ওষুধ বাকি ভেড়াগুলোকে খাওয়াতে বলেন',\n",
              "  'বুধবার সকাল ছয়টার দিকে তিনি ওই ওষুধের অর্ধেকটা পানিতে মিশিয়ে টি ভেড়াকে খাইয়ে দেন',\n",
              "  'আফজাল হোসেন কাঁদতে কাঁদতে বলেন ওষুধ খাওয়ানোর পরপরই ভেড়াগুলো ছটফট করতে থাকে',\n",
              "  'আধা ঘণ্টার মধ্যেই ভেড়া মারা যেতে শুরু করে',\n",
              "  'একে একে বেলা তিনটা পর্যন্ত টি মারা যায়',\n",
              "  'ওষুধ খাওয়ানো বাকি টি ভেড়া অসুস্থ অবস্থায় শুয়ে আছে',\n",
              "  'আশঙ্কা করছেন এগুলোও মারা যাবে',\n",
              "  'তিনি বলেন এই ভেড়াগুলোই ছিল তাঁর সম্বল',\n",
              "  'এগুলো মারা গেলে কীভাবে সংসার চালাবেন সেটাই ভেবে পাচ্ছেন না',\n",
              "  'এই ভেড়া পালন করতে গিয়ে মানুষের কাছে লক্ষাধিক টাকা দেনা হয়েছেন',\n",
              "  'যে দেনা পরিশোধ করার ক্ষমতা তাঁর আর থাকল না',\n",
              "  'আফজাল হোসেনের স্ত্রী আরজিনা বেগম  বলেন তাঁদের বিয়ে হয়েছে প্রায়  বছর',\n",
              "  'কিন্তু কোনো সন্তান হয়নি',\n",
              "  'এই ভেড়াগুলোকে তাঁরা সন্তানের মতো লালনপালন করতেন',\n",
              "  'এগুলো তাঁদের কাছে একেকটি সন্তান বলে তিনি কান্না করতে থাকেন',\n",
              "  'গ্রামের বাসিন্দা জাহাবক্স মণ্ডল বলেন আফজাল হোসেন হতদরিদ্র একজন মানুষ',\n",
              "  'এই ক্ষতি তাঁদের সামাল দেওয়া কষ্টকর হবে বলে তিনি মন্তব্য করেন',\n",
              "  'জানতে চাইলে কালীগঞ্জ উপজেলা প্রাণিসম্পদ কর্মকর্তা মো আতিকুজ্জামান বলেন ভেড়ার মালিক মঙ্গলবার তাঁদের অফিসে এসেছিলেন',\n",
              "  'সবকিছু শুনে তাঁর ভেড়াগুলোর জন্য কৃমির ওষুধ দেওয়া হয়',\n",
              "  'সেগুলো তিনি যথানিয়মে খাওয়ালে এভাবে মারা যাওয়ার কথা নয়',\n",
              "  'এরপরও কেন মারা গেল তা নিশ্চিত হতে তাঁরা নমুনা সংগ্রহ করেছেন',\n",
              "  'এই নমুনা পরীক্ষার পর বোঝা যাবে মৃত্যুর কারণ'],\n",
              " ['নোয়াখালীতে সর্বশেষ  দিনের মধ্যে করোনা রোগী শনাক্তের হার সর্বনিম্ন ছিল বুধবার',\n",
              "  'নমুনা পরীক্ষার তুলনায় এদিন শনাক্তের হার ছিল  দশমিক  শতাংশ',\n",
              "  'জনের নমুনা পরীক্ষা করে করোনা শনাক্ত হয়েছে  জনের',\n",
              "  'সন্ধ্যায় জেলা সিভিল সার্জনের কার্যালয় সূত্রে এ তথ্য জানা গেছে',\n",
              "  'এর আগে এক মাস  দিনের মধ্যে সর্বনিম্ন শনাক্তের হার ছিল  আগস্ট',\n",
              "  'এই হার  দশমিক  শতাংশ',\n",
              "  'ওই দিন টি নমুনা পরীক্ষা করে করোনা শনাক্ত হয়েছিল  জনের',\n",
              "  'সিভিল সার্জনের কার্যালয় সূত্রে জানা গেছে বুধবার জেলার দুটি করোনা পরীক্ষা কেন্দ্রে টি নমুনা পরীক্ষা করা হয়েছে',\n",
              "  'এর মধ্যে  জনের শরীরে করোনার সংক্রমণ শনাক্ত হয়েছে',\n",
              "  'বাকিদের ফলাফল নেগেটিভ',\n",
              "  'সূত্র জানায় করোনা শনাক্ত হওয়া নতুন  জন রোগীর মধ্যে সদর উপজেলার  জন সুবর্ণচরের একজন বেগমগঞ্জের  জন সোনাইমুড়ীর  জন চাটখিলের  জন ও সেনবাগের  জন রয়েছেন',\n",
              "  'সিভিল সার্জন চিকিৎসক মাসুম ইফতেখার  দিনের মধ্যে করোনা রোগী শনাক্তের হার সর্বনিম্ন পর্যায়ে পৌঁছার বিষয়টি নিশ্চিত করেছেন',\n",
              "  'প্রথম আলোকে তিনি বলেন কয়েক দিন ধরে জেলায় সংক্রমণের হার কমতির দিকে',\n",
              "  'একই সঙ্গে মারা যাওয়ার ঘটনাও কম ঘটছে',\n",
              "  'সর্বশেষ  ঘণ্টায় কারও মৃত্যুর তথ্য পাওয়া যায়নি',\n",
              "  'সিভিল সার্জন জানান সংক্রমণ নিয়ন্ত্রণে রাখতে স্বাস্থ্যবিধি মেনে চলতে লোকজনকে বাধ্য করাসহ বাড়ি বাড়ি লকডাউন নিশ্চিত করার ওপরই তাঁরা এখন বেশি জোর দিচ্ছেন',\n",
              "  'ইতিমধ্যে ভালো ফল পাওয়া গেছে'],\n",
              " ['কক্সবাজারেরর উখিয়া ও টেকনাফের টি আশ্রয়শিবিরে প্রথম ধাপের সাত দিনব্যাপী টিকাদান কর্মসূচির আওতায় টিকা নিয়েছেন  হাজার  রোহিঙ্গা',\n",
              "  'এর মধ্যে পুরুষ  হাজার  ও নারী  হাজার  জন',\n",
              "  'প্রথম ধাপের টিকার জন্য নিবন্ধন করা হয়  হাজার  জন রোহিঙ্গার',\n",
              "  'যাঁদের বয়স  বছরের বেশি',\n",
              "  'টিকা না পাওয়া  হাজার  জন রোহিঙ্গাকে পরবর্তী সুবিধাজনক সময়ে টিকা দেওয়া হবে',\n",
              "  'সিভিল সার্জনের কার্যালয় ও সংশ্লিষ্ট সূত্র জানায় বুধবার কর্মসূচির শেষ দিনে উখিয়া ও টেকনাফের  আশ্রয়শিবিরে টি কেন্দ্রে টিকা নেন প্রায়  হাজার রোহিঙ্গা',\n",
              "  'বঙ্গোপসাগরে সৃষ্ট লঘুচাপ ও বৈরী পরিবেশের কারণে সকাল থেকে বৃষ্টিপাত হওয়ায় বুধবারও টিকা প্রয়োগের লক্ষ্যমাত্রা পূরণ হয়নি',\n",
              "  'টিকার জন্য প্রতিদিন লক্ষ্যমাত্রা নির্ধারণ ছিল সাত হাজার',\n",
              "  'কিন্তু প্রতিদিন গড়ে টিকা নিয়েছেন পাঁচ হাজার রোহিঙ্গা',\n",
              "  'সাপ্তাহিক ছুটি ও জাতীয় শোক দিবস থাকায়  ও  আগস্ট টিকাদান বন্ধ ছিল',\n",
              "  'জাতিসংঘের উদ্বাস্তুবিষয়ক সংস্থা ইউএনএইচসিআরের সহযোগিতায় রোহিঙ্গা শিবিরে করোনার টিকাদান কর্মসূচি বাস্তবায়ন করছে সরকারের শরণার্থী ত্রাণ ও প্রত্যাবাসন কমিশনারের আরআরআরসি কার্যালয়',\n",
              "  'আরআরআরসি কার্যালয়ের প্রধান স্বাস্থ্য সমন্বয়কারী আবু তোহা এম আর এইচ ভূঁইয়া বলেন সাত দিনব্যাপী টিকাদান কর্মসূচির প্রধম ধাপে  হাজারের বেশি রোহিঙ্গা টিকা নিয়েছেন',\n",
              "  'আগামী দুই দিন টিকার নিবন্ধন যাচাই করা হবে',\n",
              "  'এরপর বাদ পড়া রোহিঙ্গাদের জন্য আরও দুই দিন টিকাদান কার্যক্রম চালানো হবে',\n",
              "  'রোহিঙ্গাদের দেওয়া হয়েছে চীনের সিনোফার্মের টিকা',\n",
              "  'সালের  আগস্টের পর মিয়ানমার সেনাবাহিনীর অত্যাচারনির্যাতনের মুখে অন্তত আট লাখ রোহিঙ্গা পালিয়ে বাংলাদেশে আশ্রয় নেয়',\n",
              "  'এর আগে পালিয়ে আসে আরও কয়েক লাখ',\n",
              "  'বর্তমানে উখিয়া ও টেকনাফের টি আশ্রয়শিবিরে নিবন্ধিত রোহিঙ্গার সংখ্যা সাড়ে  লাখ'],\n",
              " ['বাংলাদেশ সেনাবাহিনী প্রধান জেনারেল এস এম শফিউদ্দিন আহমেদ আট দিনের সরকারি সফরে তুরস্ক গেছেন',\n",
              "  'আজ বুধবার সকালে তুরস্কের উদ্দেশে তিনি ঢাকা ত্যাগ করেন',\n",
              "  'আন্তবাহিনী জনসংযোগ পরিদপ্তর আইএসপিআর থেকে পাঠানো সংবাদ বিজ্ঞপ্তিতে এ কথা জানানো হয়',\n",
              "  'সফরকালে সেনাপ্রধান আট সদস্যের একটি প্রতিনিধিদলের নেতৃত্ব দেবেন',\n",
              "  'জেনারেল শফিউদ্দিন আহমেদ সফরে তুরস্কের প্রতিরক্ষামন্ত্রী সহকারী প্রতিরক্ষামন্ত্রী ডিফেন্স ইন্ডাস্ট্রিজের প্রেসিডেন্ট তুর্কি সশস্ত্র বাহিনীর চিফ অব জেনারেল স্টাফ ল্যান্ড ফোর্স কমান্ডার এবং অন্য ঊর্ধ্বতন সামরিক কর্মকর্তাদের সঙ্গে সৌজন্য সাক্ষাৎ করবেন',\n",
              "  'আইএসপিআর জানিয়েছে এ সফরে জেনারেল এস এম শফিউদ্দিন দুই দেশের সেনাবাহিনীর মধ্যকার সম্পর্ক আরও জোরদার এবং পারস্পরিক সহযোগিতার বিষয়ে আলোচনা করবেন',\n",
              "  'তুরস্কের জাদুঘরসহ বিভিন্ন ঐতিহাসিক স্থানও পরিদর্শন করবেন বাংলাদেশ সেনাপ্রধান',\n",
              "  'এ ছাড়া তুরস্কে অবস্থিত বাংলাদেশ হাইকমিশনেও মতবিনিময় করবেন তিনি',\n",
              "  'আগস্ট সেনাবাহিনীর প্রধানের দেশে ফেরার কথা'],\n",
              " ['নরসিংদীতে এক নারী শ্রমিককে মাইক্রোবাসের ভেতরে দল বেঁধে ধর্ষণের অভিযোগ পাওয়া গেছে',\n",
              "  'গতকাল মঙ্গলবার সন্ধ্যায় সদর উপজেলার পশ্চিমপাড়া গ্রামের বেলতলা এলাকায় এ ঘটনা ঘটে',\n",
              "  'এ ঘটনায়  আজ বুধবার দুপুরে ওই নারী শ্রমিক তিনজনকে আসামি করে নরসিংদী মডেল থানায় মামলা করেছেন',\n",
              "  'ওই নারী শ্রমিককে ধর্ষণের অভিযোগে হওয়া মামলার তিন আসামিকে বুধবার দুপুরে নরসিংদী শহরের বিভিন্ন স্থান থেকে গ্রেপ্তার করা হয়েছে',\n",
              "  'তাঁরা হলেন কিশোরগঞ্জের করিমগঞ্জ উপজেলার গুজাদিয়া এলাকার মিজান মিয়া  নরসিংদী শহরের বাসাইল এলাকার সাইফুল ইসলাম  ও পলাশের ধনাইরচর এলাকার সোহেল মিয়া',\n",
              "  'মামলার এজাহার ও পুলিশ সূত্র জানায় পঞ্চগড় জেলার বাসিন্দা ওই নারী শ্রমিক  নরসিংদী শহরের সাটিরপাড়া মহল্লার কুমিল্লা কলোনিতে বসবাস করেন এবং স্থানীয় একটি পাওয়ারলুম কারখানায় শ্রমিক হিসেবে কাজ করেন',\n",
              "  'মুঠোফোনে কথা বলতে বলতে করিমগঞ্জ উপজেলার গুজাদিয়া এলাকার মিজান মিয়ার সঙ্গে ওই নারী শ্রমিকের পরিচয় হয়',\n",
              "  'ওই পরিচয়ের সূত্র ধরে মিজান তাঁকে তাঁর মায়ের সঙ্গে দেখা করানোর কথা বলে মঙ্গলবার সন্ধ্যায় শহরের ভেলানগর এলাকায় ডেকে নেন',\n",
              "  'পুলিশ সূত্র জানায় সন্ধ্যা সাড়ে টার দিকে মিজান ওই নারী শ্রমিককে অটোরিকশায় বেলতলা এলাকায় নিয়ে একটি সাদা রঙের মাইক্রোবাসে ওঠান',\n",
              "  'এ সময় মিজান ও মাইক্রোবাসে আগে থেকে থাকা তাঁর দুই সহযোগী সাইফুল ও সোহেল ওই নারী শ্রমিককে ধর্ষণ করেন',\n",
              "  'পরে তাঁকে গাড়ি থেকে নামিয়ে দিয়ে তাঁরা পালিয়ে যান',\n",
              "  'এ ঘটনায় রাতেই নরসিংদী মডেল থানায় লিখিত অভিযোগ দেন ওই নারী শ্রমিক',\n",
              "  'নরসিংদীর অতিরিক্ত পুলিশ সুপার ইনামুল হক সাগর জানান ওই নারী শ্রমিককে ধর্ষণের অভিযোগে করা মামলায় গ্রেপ্তার তিন আসামিকে আজ বিকেলে আদালতে পাঠানো হয়েছে',\n",
              "  'ওই তিন আসামির মধ্যে মিজান ও সোহেল আদালতে স্বীকারোক্তিমূলক জবানবন্দি দিয়েছেন']]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "#optional\n",
        "#to check the data\n",
        "test = text_data[:10]\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "0oPkNt0nJNJ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "qfun4Nojuejh"
      },
      "outputs": [],
      "source": [
        "#function to find out maximum length\n",
        "def find_max_len(text):\n",
        "  max_len = 0\n",
        "\n",
        "  for sub_list in text:\n",
        "\n",
        "    for line in sub_list:\n",
        "      l = len(line.split())\n",
        "      max_len = max(max_len,l)\n",
        "\n",
        "  return max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "grHAHcmMuhZ5"
      },
      "outputs": [],
      "source": [
        "#find out max len from summary data\n",
        "max_len = find_max_len(summary_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfU5ynhSFvlx",
        "outputId": "3b710934-dd3e-47cb-cb17-4eff0ba780ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "38v23DSDukap"
      },
      "outputs": [],
      "source": [
        "#function to find out depth of input text as it was nested list\n",
        "def maxi_width(texts):\n",
        "  max_width = 0\n",
        "  for sub_list in texts:\n",
        "    w = len(sub_list)\n",
        "    max_width = max(w,max_width)\n",
        "\n",
        "\n",
        "  return max_width\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "fDMHkbUFumvJ"
      },
      "outputs": [],
      "source": [
        "#find out max_width\n",
        "max_width = maxi_width(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNIH7_OgcdLi",
        "outputId": "aea4a730-da50-4b87-e049-b61797edcc55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "max_width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQti3VOVuouo"
      },
      "outputs": [],
      "source": [
        "#making our dataset\n",
        "dataset = list(zip(text_data,summary_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlS9QdznQ3Sw"
      },
      "outputs": [],
      "source": [
        "#skip or ignore\n",
        "old_dataset = dataset\n",
        "dataset = dataset[:700]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Aka0iDMRCVD",
        "outputId": "070f949d-87d4-4c56-cf8b-f449076f6281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm1yzSkTurlT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "yTov2sRKut09"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# reduce embedding layer 768 to 100\n",
        "# as our bert embeddeing layer is 768\n",
        "reduction_layer = nn.Linear(768, 100)\n",
        "\n",
        "# function to get sentence embedding using bert model's final hidden state\n",
        "def get_bangla_sentence_embedding(text, tokenizer, bert_model, max_len):\n",
        "\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=max_len)\n",
        "\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    reduced_embedding = reduction_layer(cls_embedding)\n",
        "\n",
        "    return reduced_embedding.squeeze(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "4k5S0NrXuwZI"
      },
      "outputs": [],
      "source": [
        "# function to pad sentence embedding to the max width as input text depth can vary\n",
        "def pad_sentence_embeddings(sentence_embeddings, max_width)\n",
        "    num_sentences, embedding_dim = sentence_embeddings.size()\n",
        "\n",
        "    if num_sentences > max_width:\n",
        "        padded_embeddings = sentence_embeddings[:max_width, :]\n",
        "    else:\n",
        "        padding = torch.zeros((max_width - num_sentences, embedding_dim), device=sentence_embeddings.device)\n",
        "        padded_embeddings = torch.cat([sentence_embeddings, padding], dim=0)\n",
        "\n",
        "    return padded_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "zirt7MXTuzwA"
      },
      "outputs": [],
      "source": [
        "# defining our dataset\n",
        "class BanglaTextSummarizerDataset(Dataset):\n",
        "\n",
        "\n",
        "  def __init__(self,data,sentence_embedding_function,tokenizer,bert_model,max_len,max_width,pad_sentence_embedding):\n",
        "    self.data = data\n",
        "    self.sentence_embedding_function = sentence_embedding_function\n",
        "    self.tokenizer = tokenizer\n",
        "    self.bert_model = bert_model\n",
        "    self.max_len = max_len\n",
        "    self.width = max_width\n",
        "    self.pse = pad_sentence_embedding\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    text,summary = self.data[idx]\n",
        "\n",
        "    text_embedding = [self.sentence_embedding_function(sentence,self.tokenizer,self.bert_model,self.max_len) for sentence in text]\n",
        "    text_embedding = torch.stack(text_embedding)\n",
        "    text_embedding = self.pse(text_embedding,self.width)\n",
        "\n",
        "    summary_input = \" \".join(summary)\n",
        "    summary_tokens = self.tokenizer(summary_input, return_tensors='pt', truncation=True, padding='max_length', max_length=self.max_len)\n",
        "\n",
        "    summary_input_ids = summary_tokens['input_ids'].squeeze(0)\n",
        "    attention_mask = summary_tokens['attention_mask'].squeeze(0)\n",
        "\n",
        "    return text_embedding, summary_input_ids, attention_mask\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "DLUCta6Zu266"
      },
      "outputs": [],
      "source": [
        "# Function to split the dataset into train, eval, and test sets\n",
        "def split_dataset(data, train_size=0.7, eval_size=0.2, test_size=0.1):\n",
        "    train_eval_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n",
        "    train_data, eval_data = train_test_split(train_eval_data, test_size=eval_size/(train_size+eval_size), random_state=42)\n",
        "    return train_data, eval_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "SyfpLsSau52g"
      },
      "outputs": [],
      "source": [
        "# load tokenizer and bert model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "#split dataset\n",
        "train,val,test = split_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "iZruq_WHu-Fw"
      },
      "outputs": [],
      "source": [
        "#creating train , val and test dataset using custom dataset class\n",
        "\n",
        "train_dataset = BanglaTextSummarizerDataset(train,get_bangla_sentence_embedding,tokenizer,bert_model,max_len,max_width,pad_sentence_embeddings)\n",
        "test_dataset = BanglaTextSummarizerDataset(test,get_bangla_sentence_embedding,tokenizer,bert_model,max_len,max_width,pad_sentence_embeddings)\n",
        "val_dataset = BanglaTextSummarizerDataset(val,get_bangla_sentence_embedding,tokenizer,bert_model,max_len,max_width,pad_sentence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "9wSiqXOfu_yJ"
      },
      "outputs": [],
      "source": [
        "#creating data loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "eval_loader = DataLoader(val_dataset, batch_size=8)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pvGp1HEvCcg",
        "outputId": "6594cbf5-6892-4fb4-d078-5a6ab809e61b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text Embedding Shape: torch.Size([20, 178, 100]) \n",
            "Summary input Shape:torch.Size([20, 39])\n"
          ]
        }
      ],
      "source": [
        "# optional\n",
        "for text_embedding,summary_input_ids, attention_mask in train_loader:\n",
        "    print(f\"text Embedding Shape: { text_embedding.shape} \")\n",
        "    print(f\"Summary input Shape:{summary_input_ids.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdmV2ou7_ZI8"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "nbLGl1e_vEr5"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Modle Architecture\n",
        "#skip this one\n",
        "'''\n",
        "class BanglaTextSummarizerModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_width, vocab_size, num_layers, num_heads, hidden_dim, max_len):\n",
        "        super(BanglaTextSummarizerModel, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_width = max_width\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Encoder: Transformer Encoder\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Decoder: Transformer Decoder\n",
        "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Embedding for the target summary (tokens)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Linear layer for output vocabulary\n",
        "        self.fc_out = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, text_embedding, input_ids, attention_mask):\n",
        "        # Encoder forward pass\n",
        "        encoder_output = self.encoder(text_embedding.permute(1, 0, 2))  # [max_width, batch_size, embedding_dim]\n",
        "\n",
        "        # Embed input_ids for the decoder\n",
        "        summary_embeddings = self.embedding(input_ids)  # [batch_size, max_len, embedding_dim]\n",
        "        summary_embeddings = summary_embeddings.permute(1, 0, 2)  # [max_len, batch_size, embedding_dim]\n",
        "\n",
        "        # Generate target mask for decoder (causal mask)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(self.max_len-1).to(input_ids.device)\n",
        "\n",
        "        # Decoder forward pass\n",
        "        decoder_output = self.decoder(summary_embeddings, encoder_output, tgt_mask=tgt_mask)  # [max_len, batch_size, embedding_dim]\n",
        "\n",
        "        # Output layer to get vocabulary logits\n",
        "        output = self.fc_out(decoder_output)  # [max_len, batch_size, vocab_size]\n",
        "\n",
        "        return output.permute(1, 0, 2)  # [batch_size, max_len, vocab_size]\n",
        "        '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "L42kp6BFkgFl"
      },
      "outputs": [],
      "source": [
        "#this to use\n",
        "# model architecture\n",
        "\n",
        "\n",
        "class BanglaTextSummarizerModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_width, vocab_size, num_layers, num_heads, hidden_dim,max_len):\n",
        "        super(BanglaTextSummarizerModel, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_len = max_len\n",
        "        self.max_width = max_width\n",
        "\n",
        "        # Encoder: Transformer Encoder\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Decoder: Transformer Decoder\n",
        "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Embedding for the target summary\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Linear layer for output vocabulary\n",
        "        self.fc_out = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, text_embeddings, input_ids,attention_mask):\n",
        "\n",
        "        # Permute text embeddings for the encoder (batch-first to sequence-first)\n",
        "        encoder_output = self.encoder(text_embeddings.permute(1, 0, 2))  # [max_width, batch_size, embedding_dim]\n",
        "\n",
        "        # Embed input_ids for the decoder\n",
        "        summary_embeddings = self.embedding(input_ids)  # [batch_size, max_len, embedding_dim]\n",
        "        summary_embeddings = summary_embeddings.permute(1, 0, 2)  # [max_len, batch_size, embedding_dim]\n",
        "\n",
        "        # Generate a causal mask for the decoder\n",
        "        tgt_seq_len = summary_embeddings.size(0)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(input_ids.device)\n",
        "\n",
        "        # Decoder forward pass\n",
        "        decoder_output = self.decoder(summary_embeddings, encoder_output, tgt_mask=tgt_mask)  # [max_len, batch_size, embedding_dim]\n",
        "\n",
        "        # Output layer to get vocabulary logits\n",
        "        output = self.fc_out(decoder_output)  # [max_len, batch_size, vocab_size]\n",
        "\n",
        "        return output.permute(1, 0, 2)  # [batch_size, max_len, vocab_size]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "YyXxLjevvHWI"
      },
      "outputs": [],
      "source": [
        "#train and val loop\n",
        "\n",
        "def train_model(model, train_loader, val_loader, tokenizer, device, num_epochs, lr, patience=3):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Training Loop\n",
        "        for text_embedding, summary_input_ids, attention_mask in train_loader:\n",
        "            input_ids = summary_input_ids\n",
        "            text_embedding = text_embedding.to(device)\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            # Prepare decoder input and target output\n",
        "            decoder_input_ids = input_ids[:, :-1]\n",
        "            decoder_output_ids = input_ids[:, 1:]\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(text_embedding, decoder_input_ids, attention_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            logits = logits.reshape(-1, logits.size(-1))\n",
        "            decoder_output_ids = decoder_output_ids.reshape(-1)\n",
        "            loss = criterion(logits, decoder_output_ids)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        # Calculate average training loss\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # Validation Loop\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for text_embedding, summary_input_ids, attention_mask in eval_loader:\n",
        "\n",
        "                input_ids = summary_input_ids\n",
        "                text_embedding = text_embedding.to(device)\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "\n",
        "                # Prepare decoder input and target output\n",
        "                decoder_input_ids = input_ids[:, :-1]\n",
        "                decoder_output_ids = input_ids[:, 1:]\n",
        "\n",
        "                # Forward pass\n",
        "                logits = model(text_embedding, decoder_input_ids, attention_mask)\n",
        "\n",
        "                # Compute loss\n",
        "                logits = logits.reshape(-1, logits.size(-1))\n",
        "                decoder_output_ids = decoder_output_ids.reshape(-1)\n",
        "                val_loss = criterion(logits, decoder_output_ids)\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "        # Calculate average validation loss\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "            print(\"Validation loss improved. Model saved.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"No improvement for {epochs_no_improve} epochs.\")\n",
        "\n",
        "        # Early stopping condition\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"Early stopping triggered. Training stopped.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcZQWRck9vdA",
        "outputId": "938c3737-a4fb-4501-e3c1-362acf3349b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 178, 100])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "#skip\n",
        "'''\n",
        "for text_embedding, summary_input_ids, attention_mask in eval_loader:\n",
        "  print(text_embedding.shape)\n",
        "\n",
        "  print(type(summary_input_ids))\n",
        "\n",
        "  break\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glSkFD-HvOXJ",
        "outputId": "c6d390e2-b5ec-4eab-d3bd-40c38db97a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/6], Train Loss: 10.4848, Val Loss: 8.8414\n",
            "Validation loss improved. Model saved.\n",
            "Epoch [2/6], Train Loss: 7.5241, Val Loss: 6.2156\n",
            "Validation loss improved. Model saved.\n",
            "Epoch [3/6], Train Loss: 5.7763, Val Loss: 5.4746\n",
            "Validation loss improved. Model saved.\n",
            "Epoch [4/6], Train Loss: 5.3666, Val Loss: 5.2986\n",
            "Validation loss improved. Model saved.\n",
            "Epoch [5/6], Train Loss: 5.1813, Val Loss: 5.1422\n",
            "Validation loss improved. Model saved.\n",
            "Epoch [6/6], Train Loss: 5.0376, Val Loss: 4.9978\n",
            "Validation loss improved. Model saved.\n",
            "Training complete.\n",
            "Best model loaded.\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model\n",
        "# Train the model\n",
        "embedding_dim = 100\n",
        "max_width = max_width\n",
        "vocab_size = tokenizer.vocab_size\n",
        "num_layers = 2\n",
        "num_heads = 1\n",
        "hidden_dim = 100\n",
        "max_len = max_len\n",
        "\n",
        "model = BanglaTextSummarizerModel(embedding_dim, max_width, vocab_size, num_layers, num_heads, hidden_dim, max_len)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_model(model, train_loader, eval_loader, tokenizer, device, num_epochs=6, lr=0.001, patience=2)\n",
        "\n",
        "# Load the best model after training\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "print(\"Best model loaded.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#You can stop here\n",
        "#model was not good enough to use in bengali QA"
      ],
      "metadata": {
        "id": "rE4mFFqbHMv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cmeC61NwsiD"
      },
      "outputs": [],
      "source": [
        "def input_text_preprocess(text_data):\n",
        "\n",
        "  processed_text = []\n",
        "\n",
        "  for sentence in text_data:\n",
        "\n",
        "      temp = clean_text(sentence)\n",
        "      temp = remove_hyphens(temp)\n",
        "      temp = remove_unwanted_char(temp)\n",
        "      processed_text.append(temp)\n",
        "    # Replace '/n' with space (if needed)\n",
        "    #processed_text = [[[t.replace('/n', \" \")] for t in document] for document in processed_text]\n",
        "  return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GUzWemjNHL0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove non-Bengali words\n",
        "def remove_non_bengali_words_1d(text_list):\n",
        "    bengali_pattern = r'[^\\u0980-\\u09FF\\s]'  # Matches non-Bengali characters\n",
        "    return [re.sub(bengali_pattern, '', sentence).strip() for sentence in text_list]"
      ],
      "metadata": {
        "id": "cR7md54uSkp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsPVWmKpwsk_",
        "outputId": "eb962a0c-875d-4669-a82f-b5306407ae20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "অক্টোবর মাসে হামাস নেতা ইয়াহিয়া সিনওয়ারকে হত্যা, লেবাননে হিজবুল্লাহর সঙ্গে যুদ্ধবিরতি ও জানুয়ারিতে নতুন মার্কিন প্রেসিডেন্ট ডোনাল্ড ট্রাম্পের অভিষেক—সব মিলিয়ে, পরিস্থিতি হামাসের অনুকূলে নেই বললেই চলে\n",
            "['অক্টোবর মাসে হামাস নেতা ইয়াহিয়া সিনওয়ারকে হত্যা লেবাননে হিজবুল্লাহর সঙ্গে যুদ্ধবিরতি ও জানুয়ারিতে নতুন মার্কিন প্রেসিডেন্ট ডোনাল্ড ট্রাম্পের অভিষেকসব মিলিয়ে পরিস্থিতি হামাসের অনুকূলে নেই বললেই চলে', 'এক ইসরায়েলি কর্মকর্তা বলেন মিসর ও কাতারের মধ্যস্থতাকারীরা বিশ্বাস করেন ইসরায়েলের প্রতি পক্ষপাতমূলক হলেও হামাস এখন জিম্মিমুক্তি ও যুদ্ধবিরতির চুক্তি মেনে নিতে পারে', '']\n",
            "tensor([[ 0.4443,  0.0753,  0.0869,  ...,  0.5878, -0.3117,  0.0410],\n",
            "        [ 0.6080,  0.1750, -0.1053,  ...,  0.4051, -0.0125, -0.2016],\n",
            "        [ 0.5691,  0.1789,  0.2714,  ...,  0.6510, -0.4486, -0.2940],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#inferrence text\n",
        "inp = \"\"\"অক্টোবর মাসে হামাস নেতা ইয়াহিয়া সিনওয়ারকে হত্যা, লেবাননে হিজবুল্লাহর সঙ্গে যুদ্ধবিরতি ও জানুয়ারিতে নতুন মার্কিন প্রেসিডেন্ট ডোনাল্ড ট্রাম্পের অভিষেক—সব মিলিয়ে, পরিস্থিতি হামাসের অনুকূলে নেই বললেই চলে।\n",
        "\n",
        "এক ইসরায়েলি কর্মকর্তা বলেন, 'মিসর ও কাতারের মধ্যস্থতাকারীরা বিশ্বাস করেন, ইসরায়েলের প্রতি পক্ষপাতমূলক হলেও হামাস এখন জিম্মি-মুক্তি ও যুদ্ধবিরতির চুক্তি মেনে নিতে পারে।'\n",
        "      \"\"\"\n",
        "#inp = list(inp)\n",
        "inp_sen = new_split_sentences(inp)\n",
        "print(inp_sen[0])\n",
        "processed_inp = input_text_preprocess(inp_sen)\n",
        "print(processed_inp)\n",
        "inp_embedding = get_bangla_sentence_embedding(processed_inp, tokenizer, bert_model, max_len)\n",
        "final_inp =pad_sentence_embeddings(inp_embedding , max_width)\n",
        "print(final_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EoYI-HF4S1t"
      },
      "outputs": [],
      "source": [
        "def generate_summary_with_embeddings(model, text_embeddings, tokenizer, max_len):\n",
        "    # Ensure text_embeddings has the shape [1, sequence_length, embedding_dim]\n",
        "    if text_embeddings.dim() == 2:  # If embeddings are [embedding_dim]\n",
        "        text_embeddings = text_embeddings.unsqueeze(0)  # Add batch dimension: [1, sequence_length, embedding_dim]\n",
        "\n",
        "    # Check the shape after reshaping\n",
        "    print(f\"Reshaped text_embeddings: {text_embeddings.shape}\")  # Should be [1, sequence_length, embedding_dim]\n",
        "\n",
        "    # Step 2: Add [CLS] token at the start of the input sequence\n",
        "    cls_token_id = tokenizer.cls_token_id\n",
        "    input_ids = torch.tensor([[cls_token_id]])  # Shape: [1, 1]\n",
        "\n",
        "    # Step 3: Create an attention mask (1 for valid tokens, 0 for padding tokens)\n",
        "    attention_mask = torch.ones(text_embeddings.shape[:2])  # Shape: [1, sequence_length]\n",
        "\n",
        "    # Step 4: Ensure text_embeddings is on the correct device (GPU or CPU)\n",
        "    text_embeddings = text_embeddings\n",
        "\n",
        "    # Step 5: Initialize the decoder input with the [CLS] token (start token)\n",
        "    decoder_input_ids = input_ids  # Start with [CLS] token as the initial sequence\n",
        "\n",
        "    # Step 6: Generate summary using the model\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        generated_ids = decoder_input_ids  # Start with [CLS] token\n",
        "        for _ in range(max_len):\n",
        "            # Forward pass through the model\n",
        "            output = model(\n",
        "                text_embeddings=text_embeddings,\n",
        "                input_ids=generated_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            # Get logits for the next token in the sequence\n",
        "            logits = output[:, -1, :]  # Get the logits for the last token in the sequence\n",
        "\n",
        "            # Apply softmax to get probabilities for each token\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "            # Get the most likely next token (argmax)\n",
        "            next_token_id = torch.argmax(probs, dim=-1)\n",
        "\n",
        "            # Append the next token to the generated sequence\n",
        "            generated_ids = torch.cat([generated_ids, next_token_id.unsqueeze(0)], dim=1)\n",
        "\n",
        "            # If the model predicts the [SEP] token, stop generation (or use another stop token)\n",
        "            if next_token_id.item() == tokenizer.sep_token_id:\n",
        "                break\n",
        "\n",
        "    # Step 7: Decode the generated_ids to get the summary text\n",
        "    summary_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MqODb3CJ17na",
        "outputId": "bc275f7a-2ca3-4d2a-ab97-2700d83ffd16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reshaped text_embeddings: torch.Size([1, 178, 100])\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ম DIGIT জনের মৃত্যুরোনা DIGIT জনের মৃত্যুরোনা DIGIT জনের মৃত্যুরোনা DIGI'"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_summary_with_embeddings(model, final_inp, tokenizer, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "x1sEsnRS3bbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7dd521b-522f-4d99-bc71-ca0bf0e07ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 1: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 2: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের DIGIT জনের DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের\n",
            "Prediction 3: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 4: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 5: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 6: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের DIGIT জনের\n",
            "Prediction 7: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের\n",
            "Prediction 8: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 9: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DI\n",
            "Prediction 10: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 11: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 12: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের DIGIT জনের মৃত্যুা\n",
            "Prediction 13: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা\n",
            "Prediction 14: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 15: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 16: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের\n",
            "Prediction 17: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 18: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 19: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 20: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 21: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 22: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 23: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 24: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 25: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 26: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্য\n",
            "Prediction 27: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের\n",
            "Prediction 28: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের DIGIT জনের DIGIT জনের DIGIT জনের\n",
            "Prediction 29: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 30: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 31: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DIGIT জনের মৃত্যুা DIGIT জনের DI\n",
            "Prediction 32: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT জনের মৃত্যুা DIGIT\n",
            "Prediction 33: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 34: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 35: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 36: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 37: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 38: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 39: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 40: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 41: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 42: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 43: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 44: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 45: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 46: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 47: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 48: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 49: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n",
            "Prediction 50: DIGIT জনের মৃত্যু DIGIT জনের মৃত্যুা\n"
          ]
        }
      ],
      "source": [
        "def inference(model, test_loader, tokenizer, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text_embedding, summary_input_ids, attention_mask in test_loader:\n",
        "            # Move tensors to the appropriate device\n",
        "            text_embedding = text_embedding.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            # Decoder input starts with the <BOS> token (beginning of sequence)\n",
        "            bos_token_id = tokenizer.cls_token_id\n",
        "            eos_token_id = tokenizer.sep_token_id\n",
        "            pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "            batch_size = text_embedding.size(0)\n",
        "            decoder_input_ids = torch.tensor([[bos_token_id] for _ in range(batch_size)], device=device)\n",
        "\n",
        "            generated_sequences = []\n",
        "\n",
        "            for _ in range(100):  # Assuming a maximum sequence length of 100\n",
        "                # Forward pass\n",
        "                logits = model(text_embedding, decoder_input_ids, attention_mask)\n",
        "\n",
        "                # Get the next token (argmax from logits)\n",
        "                next_token_logits = logits[:, -1, :]\n",
        "                next_token_ids = torch.argmax(next_token_logits, dim=-1).unsqueeze(-1)\n",
        "\n",
        "                # Append the next token to the sequence\n",
        "                decoder_input_ids = torch.cat([decoder_input_ids, next_token_ids], dim=1)\n",
        "\n",
        "                # Stop generating if all sequences in the batch hit the <EOS> token\n",
        "                if (next_token_ids == eos_token_id).all():\n",
        "                    break\n",
        "\n",
        "            # Convert token IDs to text\n",
        "            for seq in decoder_input_ids:\n",
        "                decoded_seq = tokenizer.decode(seq, skip_special_tokens=True)\n",
        "                generated_sequences.append(decoded_seq)\n",
        "\n",
        "            predictions.extend(generated_sequences)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "# Load the saved model\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# Perform inference\n",
        "predictions = inference(model, test_loader, tokenizer, device)\n",
        "\n",
        "# Display results\n",
        "for idx, prediction in enumerate(predictions):\n",
        "    print(f\"Prediction {idx + 1}: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0w3RUmuv2oB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleEncoderDecoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_len):\n",
        "        super(SimpleEncoderDecoder, self).__init__()\n",
        "\n",
        "        # Encoder does not need an embedding layer, as you're using BERT embeddings\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Embedding layer for target summary_input_ids (token IDs)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Fully connected layer for generating logits\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "        self.max_len = max_len  # Max length for the output sequence\n",
        "\n",
        "    def forward(self, text_embedding, summary_input_ids):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            text_embedding (torch.Tensor): Input sentence embeddings from BERT (shape: [batch_size, max_width, embedding_dim])\n",
        "            summary_input_ids (torch.Tensor): Target token IDs (shape: [batch_size, max_len])\n",
        "        \"\"\"\n",
        "        # Pass the text_embedding (BERT embeddings) through the LSTM\n",
        "        lstm_out, (hidden, cell) = self.rnn(text_embedding)  # Shape: [batch_size, max_width, hidden_dim]\n",
        "\n",
        "        # Embed the target summary_input_ids for the decoder\n",
        "        embedded_target = self.embedding(summary_input_ids)  # Shape: [batch_size, max_len, embedding_dim]\n",
        "\n",
        "        # Initialize the hidden and cell state for the decoder (from encoder's hidden state)\n",
        "        decoder_input = embedded_target[:, 0, :]  # Start with the first token in the target sequence\n",
        "\n",
        "        decoder_outputs = []\n",
        "\n",
        "        # Loop through each time step of the target sequence (max_len)\n",
        "        for t in range(0, self.max_len):  # Skip the first token because it is already used\n",
        "            # Pass decoder input through LSTM, using the encoder's hidden state\n",
        "            decoder_out, (hidden, cell) = self.rnn(decoder_input.unsqueeze(1), (hidden, cell))  # LSTM takes (input, (hidden, cell))\n",
        "\n",
        "            # Get logits for the current time step (output vocabulary size scores)\n",
        "            logit = self.fc(decoder_out.squeeze(1))  # Shape: [batch_size, vocab_size]\n",
        "\n",
        "            # Save the logit to the outputs list (for all time steps)\n",
        "            decoder_outputs.append(logit)\n",
        "\n",
        "            # Get the next decoder input as the current token (teacher forcing)\n",
        "            decoder_input = self.embedding(summary_input_ids[:, t])  # Next token as input\n",
        "\n",
        "        # Stack the logits for all time steps [batch_size, max_len, vocab_size]\n",
        "        decoder_outputs = torch.stack(decoder_outputs, dim=1)\n",
        "\n",
        "        return decoder_outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzXBuuZcT-XE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_model(model, train_loader, optimizer, criterion, device, num_epochs=20):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        # Loop over batches\n",
        "        for batch_idx, (text_embedding, summary_input_ids, attention_mask) in enumerate(train_loader):\n",
        "            text_embedding = text_embedding.to(device)\n",
        "            summary_input_ids = summary_input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            #print(f\"summary input ids {summary_input_ids.shape}\")\n",
        "            #summary_input_ids = summary_input_ids[:-1]\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through the model\n",
        "            output = model(text_embedding, summary_input_ids)\n",
        "\n",
        "                        # Check the shape of output and target to ensure they match\n",
        "            #print(f\"Output shape: {output.shape}\")\n",
        "            #print(f\"Target shape: {summary_input_ids.shape}\")\n",
        "\n",
        "            # Flatten the logits and target for loss calculation\n",
        "            output = output.view(-1, output.size(-1))  # [batch_size * max_len, vocab_size]\n",
        "            summary_input_ids = summary_input_ids.view(-1)\n",
        "              # [batch_size * max_len]\n",
        "\n",
        "            # Compute loss, ignoring padding tokens using attention_mask\n",
        "            loss = criterion(output, summary_input_ids)\n",
        "\n",
        "            # Backward pass and optimization step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss for the current epoch\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Average loss for the epoch\n",
        "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "DsnmwzRlUHJL",
        "outputId": "82fc2c9e-e328-4c81-971d-744e4f7c2fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Batch [0/2], Loss: 11.7088\n",
            "Epoch [1/20] completed. Average Loss: 11.7090\n",
            "Epoch [2/20], Batch [0/2], Loss: 11.6532\n",
            "Epoch [2/20] completed. Average Loss: 11.6568\n",
            "Epoch [3/20], Batch [0/2], Loss: 11.6100\n",
            "Epoch [3/20] completed. Average Loss: 11.6038\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-a96f00b24849>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-4bf1ec1c4702>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, device, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Loop over batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0msummary_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-d61c01b04b0c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-d61c01b04b0c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-cf9fc203f256>\u001b[0m in \u001b[0;36mget_bangla_sentence_embedding\u001b[0;34m(text, tokenizer, bert_model, max_len)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Get model output (hidden states)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# CLS token embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize model and other components\n",
        "embedding_dim = 100  # Example embedding dimension (e.g., BERT's embedding size)\n",
        "hidden_dim = 100\n",
        "vocab_size = tokenizer.vocab_size  # Example vocab size\n",
        "max_len = max_len  # Max length of the generated summary\n",
        "\n",
        "# Create a model instance\n",
        "model = SimpleEncoderDecoder(embedding_dim, hidden_dim, vocab_size, max_len)\n",
        "\n",
        "# Move model to GPU (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Assuming 0 is padding index in the target summary\n",
        "\n",
        "# Assuming train_loader is your DataLoader for training data\n",
        "# train_loader = DataLoader(your_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, criterion, device, num_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS31-TyTUVag"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}